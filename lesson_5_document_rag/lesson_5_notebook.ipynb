{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f818581a",
   "metadata": {},
   "source": [
    "# Lesson 5: Document RAG with LlamaIndex\n",
    "\n",
    "In this lesson, we'll learn how to create a Retrieval-Augmented Generation (RAG) system that can process and query documents using LlamaIndex. This approach allows our AI agent to answer questions based on specific document content, making it perfect for document analysis, knowledge bases, and content-specific Q&A systems.\n",
    "\n",
    "We'll build a complete document RAG solution that can handle multiple document formats and provide accurate, source-attributed responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dd7803",
   "metadata": {},
   "source": [
    "## Lesson Objectives\n",
    "\n",
    "By the end of this lesson, you will be able to:\n",
    "\n",
    "1. Set up and configure LlamaIndex for document processing\n",
    "2. Load and index various document formats (text, PDF, Word, etc.)\n",
    "3. Create vector embeddings for semantic search\n",
    "4. Build a basic RAG pipeline for document Q&A\n",
    "5. Implement advanced retrieval strategies and filtering\n",
    "6. Use LlamaIndex agents for complex document analysis\n",
    "7. Create a conversational interface for document exploration\n",
    "8. Handle multi-document queries and source attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ca23a3",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's set up our environment with the necessary libraries for document RAG.\n",
    "\n",
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex \n",
    "- !pip install llama-index-embeddings-azure-openai\n",
    "- !pip install llama-index-llms-azure-openai\n",
    "- !pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82e1508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install llama-index openai python-dotenv tiktoken chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e76b705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# LlamaIndex imports\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex, \n",
    "    SimpleDirectoryReader, \n",
    "    StorageContext, \n",
    "    load_index_from_storage,\n",
    "    Settings\n",
    ")\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# logging.basicConfig(\n",
    "#     stream=sys.stdout, level=logging.INFO\n",
    "# )  # logging.DEBUG for more verbose output\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "\n",
    "# Additional utilities\n",
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a352106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API keys and configuration\n",
    "API_KEY = os.environ.get(\"AZURE_OPENAI_KEY\") \n",
    "API_ENDPOINT = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "API_VERSION = os.environ.get(\"AZURE_OPENAI_VERSION\")\n",
    "MODEL = os.environ.get(\"AZURE_OPENAI_MODEL\")\n",
    "\n",
    "# Embedding configuration\n",
    "EMBEDDINGS_API_KEY = os.environ.get(\"AZURE_OPENAI_EMBEDDINGS_API_KEY\")\n",
    "EMBEDDINGS_API_ENDPOINT = os.environ.get(\"AZURE_OPENAI_EMBEDDINGS_ENDPOINT\")\n",
    "EMBEDDINGS_DEPLOYMENT_NAME = os.environ.get(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME\")\n",
    "EMBEDDINGS_API_VERSION = os.environ.get(\"AZURE_OPENAI_EMBEDDINGS_API_VERSION\")\n",
    "EMBEDDINGS_MODEL = os.environ.get(\"AZURE_OPENAI_EMBEDDINGS_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1397e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAI(\n",
    "    model=MODEL,\n",
    "    deployment_name=AZURE_DEPLOYMENT,\n",
    "    api_key=API_KEY,\n",
    "    azure_endpoint=API_ENDPOINT,\n",
    "    api_version=API_VERSION,\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=EMBEDDINGS_MODEL,\n",
    "    deployment_name=EMBEDDINGS_DEPLOYMENT_NAME,\n",
    "    api_key=EMBEDDINGS_API_KEY,\n",
    "    azure_endpoint=EMBEDDINGS_API_ENDPOINT,\n",
    "    api_version=EMBEDDINGS_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc5b34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Azure OpenAI configuration loaded successfully\n",
      "ðŸ“‹ Using model: gpt-4o-mini\n",
      "ðŸ“‹ Using deployment: gpt-4o-mini-v1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Check if the necessary API keys are available\n",
    "if not API_KEY:\n",
    "    print(\"âš ï¸ Azure OpenAI API key not found. Please set the AZURE_OPENAI_KEY environment variable.\")\n",
    "else:\n",
    "    print(\"âœ… Azure OpenAI configuration loaded successfully\")\n",
    "    print(f\"ðŸ“‹ Using model: {MODEL}\")\n",
    "    print(f\"ðŸ“‹ Using deployment: {AZURE_DEPLOYMENT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6769b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ LlamaIndex configured with Azure OpenAI\n",
      "ðŸ“Š Chunk size: 1024\n",
      "ðŸ“Š Chunk overlap: 200\n"
     ]
    }
   ],
   "source": [
    "# Configure LlamaIndex with Azure OpenAI\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=AZURE_DEPLOYMENT,\n",
    "    api_key=API_KEY,\n",
    "    azure_endpoint=API_ENDPOINT,\n",
    "    api_version=API_VERSION,\n",
    "    model=MODEL,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# Configure embedding model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    deployment_name=EMBEDDINGS_DEPLOYMENT_NAME,  # Update with your embedding deployment\n",
    "    api_key=API_KEY,\n",
    "    azure_endpoint=API_ENDPOINT,\n",
    "    api_version=API_VERSION,\n",
    ")\n",
    "\n",
    "# Set global configurations\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 1024\n",
    "Settings.chunk_overlap = 200\n",
    "\n",
    "print(\"ðŸ”§ LlamaIndex configured with Azure OpenAI\")\n",
    "print(f\"ðŸ“Š Chunk size: {Settings.chunk_size}\")\n",
    "print(f\"ðŸ“Š Chunk overlap: {Settings.chunk_overlap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d6107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c7a87",
   "metadata": {},
   "source": [
    "## 2. Loading and Processing Documents\n",
    "\n",
    "Let's start by loading and processing our sample documents. LlamaIndex makes it easy to load various document formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b7f7b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SimpleDirectoryReader in module llama_index.core.readers.file.base:\n",
      "\n",
      "class SimpleDirectoryReader(llama_index.core.readers.base.BaseReader, llama_index.core.readers.base.ResourcesReaderMixin, FileSystemReaderMixin)\n",
      " |  SimpleDirectoryReader(\n",
      " |      input_dir: 'Optional[Union[Path, str]]' = None,\n",
      " |      input_files: 'Optional[list]' = None,\n",
      " |      exclude: 'Optional[list]' = None,\n",
      " |      exclude_hidden: 'bool' = True,\n",
      " |      exclude_empty: 'bool' = False,\n",
      " |      errors: 'str' = 'ignore',\n",
      " |      recursive: 'bool' = False,\n",
      " |      encoding: 'str' = 'utf-8',\n",
      " |      filename_as_id: 'bool' = False,\n",
      " |      required_exts: 'Optional[list[str]]' = None,\n",
      " |      file_extractor: 'Optional[dict[str, BaseReader]]' = None,\n",
      " |      num_files_limit: 'Optional[int]' = None,\n",
      " |      file_metadata: 'Optional[Callable[[str], dict]]' = None,\n",
      " |      raise_on_error: 'bool' = False,\n",
      " |      fs: 'fsspec.AbstractFileSystem | None' = None\n",
      " |  ) -> 'None'\n",
      " |\n",
      " |  Simple directory reader.\n",
      " |\n",
      " |  Load files from file directory.\n",
      " |  Automatically select the best file reader given file extensions.\n",
      " |\n",
      " |  Args:\n",
      " |      input_dir (Union[Path, str]): Path to the directory.\n",
      " |      input_files (List): List of file paths to read\n",
      " |          (Optional; overrides input_dir, exclude)\n",
      " |      exclude (List): glob of python file paths to exclude (Optional)\n",
      " |      exclude_hidden (bool): Whether to exclude hidden files (dotfiles).\n",
      " |      exclude_empty (bool): Whether to exclude empty files (Optional).\n",
      " |      encoding (str): Encoding of the files.\n",
      " |          Default is utf-8.\n",
      " |      errors (str): how encoding and decoding errors are to be handled,\n",
      " |            see https://docs.python.org/3/library/functions.html#open\n",
      " |      recursive (bool): Whether to recursively search in subdirectories.\n",
      " |          False by default.\n",
      " |      filename_as_id (bool): Whether to use the filename as the document id.\n",
      " |          False by default.\n",
      " |      required_exts (Optional[List[str]]): List of required extensions.\n",
      " |          Default is None.\n",
      " |      file_extractor (Optional[Dict[str, BaseReader]]): A mapping of file\n",
      " |          extension to a BaseReader class that specifies how to convert that file\n",
      " |          to text. If not specified, use default from DEFAULT_FILE_READER_CLS.\n",
      " |      num_files_limit (Optional[int]): Maximum number of files to read.\n",
      " |          Default is None.\n",
      " |      file_metadata (Optional[Callable[[str], Dict]]): A function that takes\n",
      " |          in a filename and returns a Dict of metadata for the Document.\n",
      " |          Default is None.\n",
      " |      raise_on_error (bool): Whether to raise an error if a file cannot be read.\n",
      " |      fs (Optional[fsspec.AbstractFileSystem]): File system to use. Defaults\n",
      " |      to using the local file system. Can be changed to use any remote file system\n",
      " |      exposed via the fsspec interface.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      SimpleDirectoryReader\n",
      " |      llama_index.core.readers.base.BaseReader\n",
      " |      llama_index.core.readers.base.ResourcesReaderMixin\n",
      " |      FileSystemReaderMixin\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(\n",
      " |      self,\n",
      " |      input_dir: 'Optional[Union[Path, str]]' = None,\n",
      " |      input_files: 'Optional[list]' = None,\n",
      " |      exclude: 'Optional[list]' = None,\n",
      " |      exclude_hidden: 'bool' = True,\n",
      " |      exclude_empty: 'bool' = False,\n",
      " |      errors: 'str' = 'ignore',\n",
      " |      recursive: 'bool' = False,\n",
      " |      encoding: 'str' = 'utf-8',\n",
      " |      filename_as_id: 'bool' = False,\n",
      " |      required_exts: 'Optional[list[str]]' = None,\n",
      " |      file_extractor: 'Optional[dict[str, BaseReader]]' = None,\n",
      " |      num_files_limit: 'Optional[int]' = None,\n",
      " |      file_metadata: 'Optional[Callable[[str], dict]]' = None,\n",
      " |      raise_on_error: 'bool' = False,\n",
      " |      fs: 'fsspec.AbstractFileSystem | None' = None\n",
      " |  ) -> 'None'\n",
      " |      Initialize with parameters.\n",
      " |\n",
      " |  async aload_data(\n",
      " |      self,\n",
      " |      show_progress: 'bool' = False,\n",
      " |      num_workers: 'int | None' = None,\n",
      " |      fs: 'fsspec.AbstractFileSystem | None' = None\n",
      " |  ) -> 'list[Document]'\n",
      " |      Load data from the input directory.\n",
      " |\n",
      " |      Args:\n",
      " |          show_progress (bool): Whether to show tqdm progress bars. Defaults to False.\n",
      " |          num_workers  (Optional[int]): Number of workers to parallelize data-loading over.\n",
      " |          fs (Optional[fsspec.AbstractFileSystem]): File system to use. If fs was specified\n",
      " |              in the constructor, it will override the fs parameter here.\n",
      " |\n",
      " |      Returns:\n",
      " |          List[Document]: A list of documents.\n",
      " |\n",
      " |  async aload_resource(self, resource_id: 'str', *args: 'Any', **kwargs: 'Any') -> 'list[Document]'\n",
      " |      Read file from filesystem and return documents asynchronously.\n",
      " |\n",
      " |  get_resource_info(self, resource_id: 'str', *args: 'Any', **kwargs: 'Any') -> 'dict'\n",
      " |      Get a dictionary of information about a specific resource.\n",
      " |\n",
      " |      Args:\n",
      " |          resource (str): The resource identifier.\n",
      " |\n",
      " |      Returns:\n",
      " |          Dict: A dictionary of information about the resource.\n",
      " |\n",
      " |  is_empty_file(self, path: 'Path | PurePosixPath') -> 'bool'\n",
      " |\n",
      " |  is_hidden(self, path: 'Path | PurePosixPath') -> 'bool'\n",
      " |\n",
      " |  iter_data(self, show_progress: 'bool' = False) -> 'Generator[list[Document], Any, Any]'\n",
      " |      Load data iteratively from the input directory.\n",
      " |\n",
      " |      Args:\n",
      " |          show_progress (bool): Whether to show tqdm progress bars. Defaults to False.\n",
      " |\n",
      " |      Returns:\n",
      " |          Generator[List[Document]]: A list of documents.\n",
      " |\n",
      " |  list_resources(self, *args: 'Any', **kwargs: 'Any') -> 'list[str]'\n",
      " |      List files in the given filesystem.\n",
      " |\n",
      " |  load_data(\n",
      " |      self,\n",
      " |      show_progress: 'bool' = False,\n",
      " |      num_workers: 'int | None' = None,\n",
      " |      fs: 'fsspec.AbstractFileSystem | None' = None\n",
      " |  ) -> 'list[Document]'\n",
      " |      Load data from the input directory.\n",
      " |\n",
      " |      Args:\n",
      " |          show_progress (bool): Whether to show tqdm progress bars. Defaults to False.\n",
      " |          num_workers  (Optional[int]): Number of workers to parallelize data-loading over.\n",
      " |          fs (Optional[fsspec.AbstractFileSystem]): File system to use. If fs was specified\n",
      " |              in the constructor, it will override the fs parameter here.\n",
      " |\n",
      " |      Returns:\n",
      " |          List[Document]: A list of documents.\n",
      " |\n",
      " |  load_resource(self, resource_id: 'str', *args: 'Any', **kwargs: 'Any') -> 'list[Document]'\n",
      " |      Load data from a specific resource.\n",
      " |\n",
      " |      Args:\n",
      " |          resource (str): The resource identifier.\n",
      " |\n",
      " |      Returns:\n",
      " |          List[Document]: A list of documents loaded from the resource.\n",
      " |\n",
      " |  read_file_content(self, input_file: 'Path', **kwargs: 'Any') -> 'bytes'\n",
      " |      Read file content.\n",
      " |\n",
      " |  supported_suffix_fn = _try_loading_included_file_formats() -> 'dict[str, Type[BaseReader]]' from llama_index.core.readers.file.base\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |\n",
      " |  async aload_file(\n",
      " |      input_file: 'Path | PurePosixPath',\n",
      " |      file_metadata: 'Callable[[str], dict]',\n",
      " |      file_extractor: 'dict[str, BaseReader]',\n",
      " |      filename_as_id: 'bool' = False,\n",
      " |      encoding: 'str' = 'utf-8',\n",
      " |      errors: 'str' = 'ignore',\n",
      " |      raise_on_error: 'bool' = False,\n",
      " |      fs: 'fsspec.AbstractFileSystem | None' = None\n",
      " |  ) -> 'list[Document]'\n",
      " |      Load file asynchronously.\n",
      " |\n",
      " |  load_file(\n",
      " |      input_file: 'Path | PurePosixPath',\n",
      " |      file_metadata: 'Callable[[str], dict]',\n",
      " |      file_extractor: 'dict[str, BaseReader]',\n",
      " |      filename_as_id: 'bool' = False,\n",
      " |      encoding: 'str' = 'utf-8',\n",
      " |      errors: 'str' = 'ignore',\n",
      " |      raise_on_error: 'bool' = False,\n",
      " |      fs: 'fsspec.AbstractFileSystem | None' = None\n",
      " |  ) -> 'list[Document]'\n",
      " |      Static method for loading file.\n",
      " |\n",
      " |      NOTE: necessarily as a static method for parallel processing.\n",
      " |\n",
      " |      Args:\n",
      " |          input_file (Path): File path to read\n",
      " |          file_metadata ([Callable[[str], Dict]]): A function that takes\n",
      " |              in a filename and returns a Dict of metadata for the Document.\n",
      " |          file_extractor (Dict[str, BaseReader]): A mapping of file\n",
      " |              extension to a BaseReader class that specifies how to convert that file\n",
      " |              to text.\n",
      " |          filename_as_id (bool): Whether to use the filename as the document id.\n",
      " |          encoding (str): Encoding of the files.\n",
      " |              Default is utf-8.\n",
      " |          errors (str): how encoding and decoding errors are to be handled,\n",
      " |              see https://docs.python.org/3/library/functions.html#open\n",
      " |          raise_on_error (bool): Whether to raise an error if a file cannot be read.\n",
      " |          fs (Optional[fsspec.AbstractFileSystem]): File system to use. Defaults\n",
      " |              to using the local file system. Can be changed to use any remote file system\n",
      " |\n",
      " |      Returns:\n",
      " |          List[Document]: loaded documents\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  __annotations__ = {'supported_suffix_fn': 'Callable'}\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from llama_index.core.readers.base.BaseReader:\n",
      " |\n",
      " |  async alazy_load_data(self, *args: Any, **load_kwargs: Any) -> Iterable[llama_index.core.schema.Document]\n",
      " |      Load data from the input directory lazily.\n",
      " |\n",
      " |  lazy_load_data(self, *args: Any, **load_kwargs: Any) -> Iterable[llama_index.core.schema.Document]\n",
      " |      Load data from the input directory lazily.\n",
      " |\n",
      " |  load_langchain_documents(self, **load_kwargs: Any) -> List[ForwardRef('LCDocument')]\n",
      " |      Load data in LangChain document format.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from llama_index.core.readers.base.BaseReader:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from llama_index.core.readers.base.ResourcesReaderMixin:\n",
      " |\n",
      " |  async aget_permission_info(self, resource_id: str, *args: Any, **kwargs: Any) -> Dict\n",
      " |      Get a dictionary of information about the permissions of a specific resource asynchronously.\n",
      " |\n",
      " |  async aget_resource_info(self, resource_id: str, *args: Any, **kwargs: Any) -> Dict\n",
      " |      Get a dictionary of information about a specific resource asynchronously.\n",
      " |\n",
      " |      Args:\n",
      " |          resource (str): The resource identifier.\n",
      " |\n",
      " |      Returns:\n",
      " |          Dict: A dictionary of information about the resource.\n",
      " |\n",
      " |  async alist_resources(self, *args: Any, **kwargs: Any) -> List[str]\n",
      " |      List of identifiers for the specific type of resources available in the reader asynchronously.\n",
      " |\n",
      " |      Returns:\n",
      " |          List[str]: A list of resources based on the reader type, such as files for a filesystem reader,\n",
      " |          channel IDs for a Slack reader, or pages for a Notion reader.\n",
      " |\n",
      " |  async alist_resources_with_info(self, *args: Any, **kwargs: Any) -> Dict[str, Dict]\n",
      " |      Get a dictionary of information about all resources asynchronously.\n",
      " |\n",
      " |      Returns:\n",
      " |          Dict[str, Dict]: A dictionary of information about all resources.\n",
      " |\n",
      " |  async aload_resources(self, resource_ids: List[str], *args: Any, **kwargs: Any) -> Dict[str, List[llama_index.core.schema.Document]]\n",
      " |      Similar ato load_data, but only for specific resources.\n",
      " |\n",
      " |      Args:\n",
      " |          resource_ids (List[str]): List of resource identifiers.\n",
      " |\n",
      " |      Returns:\n",
      " |          Dict[str, List[Document]]: A dictionary of documents loaded from the resources.\n",
      " |\n",
      " |  get_permission_info(self, resource_id: str, *args: Any, **kwargs: Any) -> Dict\n",
      " |      Get a dictionary of information about the permissions of a specific resource.\n",
      " |\n",
      " |  list_resources_with_info(self, *args: Any, **kwargs: Any) -> Dict[str, Dict]\n",
      " |      Get a dictionary of information about all resources.\n",
      " |\n",
      " |      Returns:\n",
      " |          Dict[str, Dict]: A dictionary of information about all resources.\n",
      " |\n",
      " |  load_resources(self, resource_ids: List[str], *args: Any, **kwargs: Any) -> List[llama_index.core.schema.Document]\n",
      " |      Similar to load_data, but only for specific resources.\n",
      " |\n",
      " |      Args:\n",
      " |          resource_ids (List[str]): List of resource identifiers.\n",
      " |\n",
      " |      Returns:\n",
      " |          List[Document]: A list of documents loaded from the resources.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from FileSystemReaderMixin:\n",
      " |\n",
      " |  async aread_file_content(self, input_file: 'Path', **kwargs: 'Any') -> 'bytes'\n",
      " |      A thin wrapper around read_file_content.\n",
      " |\n",
      " |      Args:\n",
      " |          input_file (Path): Path to the file.\n",
      " |\n",
      " |      Returns:\n",
      " |          bytes: File content.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_dir=\"../lesson_5_document_rag/sample_documents\",\n",
    ").load_data()\n",
    "\n",
    "help(SimpleDirectoryReader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebbcec39",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.indices.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m embed_nodes, DEFAULT_TRANSFORMATIONS\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_transformations\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 1. Turn your documents into nodes exactly as llama-index will:\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'llama_index.indices.utils'"
     ]
    }
   ],
   "source": [
    "from llama_index.indices.utils import embed_nodes, DEFAULT_TRANSFORMATIONS\n",
    "from llama_index.core import run_transformations\n",
    "\n",
    "# 1. Turn your documents into nodes exactly as llama-index will:\n",
    "nodes = run_transformations(\n",
    "    documents,\n",
    "    transformations=DEFAULT_TRANSFORMATIONS,\n",
    "    chunk_size=Settings.chunk_size,\n",
    "    chunk_overlap=Settings.chunk_overlap,\n",
    ")\n",
    "\n",
    "# 2. Check each node.text\n",
    "bad_nodes = []\n",
    "for i, node in enumerate(nodes):\n",
    "    txt = getattr(node, \"text\", None)\n",
    "    if not isinstance(txt, str):\n",
    "        bad_nodes.append((i, type(txt), repr(txt)[:100]))\n",
    "if bad_nodes:\n",
    "    print(\"Non-str node.text found:\", bad_nodes)\n",
    "else:\n",
    "    print(\"All nodes have .text as str âœ…\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8935b99",
   "metadata": {},
   "source": [
    "## 3. Creating Vector Index\n",
    "\n",
    "Now let's create a vector index from our documents. This will enable semantic search over the document content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d86fcfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Unsupported data type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# print(documents)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m index = \u001b[43mVectorStoreIndex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/llama_index/core/indices/base.py:122\u001b[39m, in \u001b[36mBaseIndex.from_documents\u001b[39m\u001b[34m(cls, documents, storage_context, show_progress, callback_manager, transformations, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m     docstore.set_document_hash(doc.id_, doc.hash)\n\u001b[32m    115\u001b[39m nodes = run_transformations(\n\u001b[32m    116\u001b[39m     documents,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    117\u001b[39m     transformations,\n\u001b[32m    118\u001b[39m     show_progress=show_progress,\n\u001b[32m    119\u001b[39m     **kwargs,\n\u001b[32m    120\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/llama_index/core/indices/vector_store/base.py:75\u001b[39m, in \u001b[36mVectorStoreIndex.__init__\u001b[39m\u001b[34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28mself\u001b[39m._embed_model = resolve_embed_model(\n\u001b[32m     71\u001b[39m     embed_model \u001b[38;5;129;01mor\u001b[39;00m Settings.embed_model, callback_manager=callback_manager\n\u001b[32m     72\u001b[39m )\n\u001b[32m     74\u001b[39m \u001b[38;5;28mself\u001b[39m._insert_batch_size = insert_batch_size\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/llama_index/core/indices/base.py:79\u001b[39m, in \u001b[36mBaseIndex.__init__\u001b[39m\u001b[34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m     nodes = nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     index_struct = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28mself\u001b[39m._index_struct = index_struct\n\u001b[32m     84\u001b[39m \u001b[38;5;28mself\u001b[39m._storage_context.index_store.add_index_struct(\u001b[38;5;28mself\u001b[39m._index_struct)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/llama_index/core/indices/vector_store/base.py:309\u001b[39m, in \u001b[36mVectorStoreIndex.build_index_from_nodes\u001b[39m\u001b[34m(self, nodes, **insert_kwargs)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(content_nodes) != \u001b[38;5;28mlen\u001b[39m(nodes):\n\u001b[32m    307\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSome nodes are missing content, skipping them...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/llama_index/core/indices/vector_store/base.py:278\u001b[39m, in \u001b[36mVectorStoreIndex._build_index_from_nodes\u001b[39m\u001b[34m(self, nodes, **insert_kwargs)\u001b[39m\n\u001b[32m    276\u001b[39m     run_async_tasks(tasks)\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_add_nodes_to_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_show_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m index_struct\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/llama_index/core/indices/vector_store/base.py:231\u001b[39m, in \u001b[36mVectorStoreIndex._add_nodes_to_index\u001b[39m\u001b[34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[39m\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m nodes_batch \u001b[38;5;129;01min\u001b[39;00m iter_batch(nodes, \u001b[38;5;28mself\u001b[39m._insert_batch_size):\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     nodes_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_node_with_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m     new_ids = \u001b[38;5;28mself\u001b[39m._vector_store.add(nodes_batch, **insert_kwargs)\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._vector_store.stores_text \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._store_nodes_override:\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[32m    236\u001b[39m         \u001b[38;5;66;03m# we need to add the nodes to the index struct and document store\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/llama_index/core/indices/vector_store/base.py:138\u001b[39m, in \u001b[36mVectorStoreIndex._get_node_with_embedding\u001b[39m\u001b[34m(self, nodes, show_progress)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_node_with_embedding\u001b[39m(\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    128\u001b[39m     nodes: Sequence[BaseNode],\n\u001b[32m    129\u001b[39m     show_progress: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    130\u001b[39m ) -> List[BaseNode]:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Get tuples of id, node, and embedding.\u001b[39;00m\n\u001b[32m    133\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    136\u001b[39m \n\u001b[32m    137\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     id_to_embed_map = \u001b[43membed_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m     results = []\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/llama_index/core/indices/utils.py:165\u001b[39m, in \u001b[36membed_nodes\u001b[39m\u001b[34m(nodes, embed_model, show_progress)\u001b[39m\n\u001b[32m    162\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    163\u001b[39m         id_to_embed_map[node.node_id] = node.embedding\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m new_embeddings = \u001b[43membed_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_text_embedding_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts_to_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m new_id, text_embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ids_to_embed, new_embeddings):\n\u001b[32m    170\u001b[39m     id_to_embed_map[new_id] = text_embedding\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/llama_index_instrumentation/dispatcher.py:319\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    316\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    322\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/llama_index/core/base/embeddings/base.py:406\u001b[39m, in \u001b[36mBaseEmbedding.get_text_embedding_batch\u001b[39m\u001b[34m(self, texts, show_progress, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    402\u001b[39m     CBEventType.EMBEDDING,\n\u001b[32m    403\u001b[39m     payload={EventPayload.SERIALIZED: \u001b[38;5;28mself\u001b[39m.to_dict()},\n\u001b[32m    404\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embeddings_cache:\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_text_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embeddings_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    408\u001b[39m         embeddings = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/llama_index/embeddings/openai/base.py:465\u001b[39m, in \u001b[36mOpenAIEmbedding._get_text_embeddings\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    456\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_retryable_get_embeddings\u001b[39m():\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m get_embeddings(\n\u001b[32m    459\u001b[39m         client,\n\u001b[32m    460\u001b[39m         texts,\n\u001b[32m    461\u001b[39m         engine=\u001b[38;5;28mself\u001b[39m._text_engine,\n\u001b[32m    462\u001b[39m         **\u001b[38;5;28mself\u001b[39m.additional_kwargs,\n\u001b[32m    463\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retryable_get_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.0-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.0-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/llama_index/embeddings/openai/base.py:458\u001b[39m, in \u001b[36mOpenAIEmbedding._get_text_embeddings.<locals>._retryable_get_embeddings\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    456\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_retryable_get_embeddings\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_text_engine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madditional_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/llama_index/embeddings/openai/base.py:169\u001b[39m, in \u001b[36mget_embeddings\u001b[39m\u001b[34m(client, list_of_text, engine, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(list_of_text) <= \u001b[32m2048\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mThe batch size should not be larger than 2048.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    167\u001b[39m list_of_text = [text.replace(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m list_of_text]\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m data = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mlist_of_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.data\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [d.embedding \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/openai/resources/embeddings.py:129\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    123\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    124\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    125\u001b[39m             ).tolist()\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/openai/_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/agentic-ai-workflows/.venv/lib/python3.13/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Unsupported data type"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(documents)\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb12fa",
   "metadata": {},
   "source": [
    "## 4. Basic RAG Query Engine\n",
    "\n",
    "Let's create a basic query engine that can answer questions based on our document content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de14c044",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33mWhat are these documents about?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m query_engine = \u001b[43mindex\u001b[49m.as_query_engine()\n\u001b[32m      3\u001b[39m answer = query_engine.query(query)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(answer.get_formatted_sources())\n",
      "\u001b[31mNameError\u001b[39m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "query = \"What are these documents about?\"\n",
    "query_engine = index.as_query_engine()\n",
    "answer = query_engine.query(query)\n",
    "\n",
    "print(answer.get_formatted_sources())\n",
    "print(\"query was:\", query)\n",
    "print(\"answer was:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bec03f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the basic query engine\n",
    "def test_basic_query(question):\n",
    "    \"\"\"Test a query and display results\"\"\"\n",
    "    print(f\"ðŸ” Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    response = query_engine.query(question)\n",
    "    \n",
    "    print(\"ðŸ¤– Answer:\")\n",
    "    print(response.response)\n",
    "    \n",
    "    # Show source information\n",
    "    print(f\"\\nðŸ“š Sources used: {len(response.source_nodes)} chunks\")\n",
    "    for i, node in enumerate(response.source_nodes, 1):\n",
    "        print(f\"  Source {i}: {node.metadata.get('file_name', 'Unknown')}\")\n",
    "        print(f\"    Score: {node.score:.3f}\")\n",
    "        print(f\"    Text: {node.text[:150]}...\")\n",
    "        print()\n",
    "    \n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb2b4cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ” Question: What is artificial intelligence?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Answer:\n",
      "Artificial Intelligence refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. It encompasses any machine that exhibits traits associated with a human mind, such as learning and problem-solving. AI can be categorized into three main types: Narrow AI, which is designed for specific tasks; General AI, a hypothetical form that can understand and apply knowledge across various tasks at a human level; and Superintelligence, which surpasses human intelligence in all aspects.\n",
      "\n",
      "ðŸ“š Sources used: 2 chunks\n",
      "  Source 1: sample1.txt\n",
      "    Score: 0.446\n",
      "    Text: Artificial Intelligence and Machine Learning: A Comprehensive Overview\n",
      "\n",
      "Introduction\n",
      "\n",
      "Artificial Intelligence (AI) and Machine Learning (ML) have beco...\n",
      "\n",
      "  Source 2: sample2.txt\n",
      "    Score: 0.247\n",
      "    Text: Serverless Computing:\n",
      "Running applications without managing servers, paying only for actual usage.\n",
      "\n",
      "Container Orchestration:\n",
      "Using technologies like K...\n",
      "\n",
      "\n",
      "============================================================\n",
      "ðŸ” Question: What are the benefits of cloud computing?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Answer:\n",
      "Artificial Intelligence refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. It encompasses any machine that exhibits traits associated with a human mind, such as learning and problem-solving. AI can be categorized into three main types: Narrow AI, which is designed for specific tasks; General AI, a hypothetical form that can understand and apply knowledge across various tasks at a human level; and Superintelligence, which surpasses human intelligence in all aspects.\n",
      "\n",
      "ðŸ“š Sources used: 2 chunks\n",
      "  Source 1: sample1.txt\n",
      "    Score: 0.446\n",
      "    Text: Artificial Intelligence and Machine Learning: A Comprehensive Overview\n",
      "\n",
      "Introduction\n",
      "\n",
      "Artificial Intelligence (AI) and Machine Learning (ML) have beco...\n",
      "\n",
      "  Source 2: sample2.txt\n",
      "    Score: 0.247\n",
      "    Text: Serverless Computing:\n",
      "Running applications without managing servers, paying only for actual usage.\n",
      "\n",
      "Container Orchestration:\n",
      "Using technologies like K...\n",
      "\n",
      "\n",
      "============================================================\n",
      "ðŸ” Question: What are the benefits of cloud computing?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Answer:\n",
      "The benefits of cloud computing include:\n",
      "\n",
      "1. **Cost Efficiency**: Reduced capital expenditure on hardware and infrastructure, pay-as-you-use pricing models, and lower operational costs through economies of scale.\n",
      "\n",
      "2. **Scalability and Flexibility**: Rapid scaling up or down based on demand, access to the latest technologies and services, and global reach and availability.\n",
      "\n",
      "3. **Reliability and Availability**: High uptime guarantees (99.9% or higher), built-in redundancy and disaster recovery, and professional management and monitoring.\n",
      "\n",
      "4. **Innovation and Speed**: Faster time-to-market for applications, access to cutting-edge technologies such as AI, ML, and IoT, and the ability to focus on core business rather than IT infrastructure.\n",
      "\n",
      "ðŸ“š Sources used: 2 chunks\n",
      "  Source 1: sample2.txt\n",
      "    Score: 0.549\n",
      "    Text: Cloud Computing: Transforming Modern Business Infrastructure\n",
      "\n",
      "Introduction\n",
      "\n",
      "Cloud computing has revolutionized how businesses and individuals access, ...\n",
      "\n",
      "  Source 2: sample2.txt\n",
      "    Score: 0.477\n",
      "    Text: Serverless Computing:\n",
      "Running applications without managing servers, paying only for actual usage.\n",
      "\n",
      "Container Orchestration:\n",
      "Using technologies like K...\n",
      "\n",
      "\n",
      "============================================================\n",
      "ðŸ” Question: Explain the different types of machine learning\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Answer:\n",
      "The benefits of cloud computing include:\n",
      "\n",
      "1. **Cost Efficiency**: Reduced capital expenditure on hardware and infrastructure, pay-as-you-use pricing models, and lower operational costs through economies of scale.\n",
      "\n",
      "2. **Scalability and Flexibility**: Rapid scaling up or down based on demand, access to the latest technologies and services, and global reach and availability.\n",
      "\n",
      "3. **Reliability and Availability**: High uptime guarantees (99.9% or higher), built-in redundancy and disaster recovery, and professional management and monitoring.\n",
      "\n",
      "4. **Innovation and Speed**: Faster time-to-market for applications, access to cutting-edge technologies such as AI, ML, and IoT, and the ability to focus on core business rather than IT infrastructure.\n",
      "\n",
      "ðŸ“š Sources used: 2 chunks\n",
      "  Source 1: sample2.txt\n",
      "    Score: 0.549\n",
      "    Text: Cloud Computing: Transforming Modern Business Infrastructure\n",
      "\n",
      "Introduction\n",
      "\n",
      "Cloud computing has revolutionized how businesses and individuals access, ...\n",
      "\n",
      "  Source 2: sample2.txt\n",
      "    Score: 0.477\n",
      "    Text: Serverless Computing:\n",
      "Running applications without managing servers, paying only for actual usage.\n",
      "\n",
      "Container Orchestration:\n",
      "Using technologies like K...\n",
      "\n",
      "\n",
      "============================================================\n",
      "ðŸ” Question: Explain the different types of machine learning\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Answer:\n",
      "Machine learning can be categorized into three main types:\n",
      "\n",
      "1. **Supervised Learning**: In this approach, algorithms learn from labeled training data to make predictions on new, unseen data. It involves tasks such as classification and regression, where the model is trained on input-output pairs.\n",
      "\n",
      "2. **Unsupervised Learning**: This type involves algorithms that find hidden patterns in data without the use of labeled examples. Common techniques include clustering, where data is grouped based on similarities, and dimensionality reduction, which simplifies data while retaining essential information.\n",
      "\n",
      "3. **Reinforcement Learning**: Here, algorithms learn through interaction with an environment. They receive rewards or penalties based on their actions, allowing them to improve their decision-making over time through trial and error.\n",
      "\n",
      "ðŸ“š Sources used: 2 chunks\n",
      "  Source 1: sample1.txt\n",
      "    Score: 0.432\n",
      "    Text: Artificial Intelligence and Machine Learning: A Comprehensive Overview\n",
      "\n",
      "Introduction\n",
      "\n",
      "Artificial Intelligence (AI) and Machine Learning (ML) have beco...\n",
      "\n",
      "  Source 2: sample2.txt\n",
      "    Score: 0.270\n",
      "    Text: Serverless Computing:\n",
      "Running applications without managing servers, paying only for actual usage.\n",
      "\n",
      "Container Orchestration:\n",
      "Using technologies like K...\n",
      "\n",
      "\n",
      "ðŸ¤– Answer:\n",
      "Machine learning can be categorized into three main types:\n",
      "\n",
      "1. **Supervised Learning**: In this approach, algorithms learn from labeled training data to make predictions on new, unseen data. It involves tasks such as classification and regression, where the model is trained on input-output pairs.\n",
      "\n",
      "2. **Unsupervised Learning**: This type involves algorithms that find hidden patterns in data without the use of labeled examples. Common techniques include clustering, where data is grouped based on similarities, and dimensionality reduction, which simplifies data while retaining essential information.\n",
      "\n",
      "3. **Reinforcement Learning**: Here, algorithms learn through interaction with an environment. They receive rewards or penalties based on their actions, allowing them to improve their decision-making over time through trial and error.\n",
      "\n",
      "ðŸ“š Sources used: 2 chunks\n",
      "  Source 1: sample1.txt\n",
      "    Score: 0.432\n",
      "    Text: Artificial Intelligence and Machine Learning: A Comprehensive Overview\n",
      "\n",
      "Introduction\n",
      "\n",
      "Artificial Intelligence (AI) and Machine Learning (ML) have beco...\n",
      "\n",
      "  Source 2: sample2.txt\n",
      "    Score: 0.270\n",
      "    Text: Serverless Computing:\n",
      "Running applications without managing servers, paying only for actual usage.\n",
      "\n",
      "Container Orchestration:\n",
      "Using technologies like K...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with sample questions\n",
    "questions = [\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"What are the benefits of cloud computing?\",\n",
    "    \"Explain the different types of machine learning\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(\"=\" * 60)\n",
    "    test_basic_query(question)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a96ac",
   "metadata": {},
   "source": [
    "## 5. Advanced Retrieval and Filtering\n",
    "\n",
    "Let's enhance our RAG system with more advanced retrieval strategies and post-processing filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00168bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Advanced query engine created!\n",
      "ðŸ“‹ Enhanced features:\n",
      "  - Similarity filtering (cutoff: 0.7)\n",
      "  - Higher initial retrieval (top 5)\n",
      "  - Post-processing for relevance\n",
      "  - Tree summarization for better responses\n"
     ]
    }
   ],
   "source": [
    "# Create advanced retriever with filters\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core import get_response_synthesizer\n",
    "\n",
    "# Create retriever with more results initially\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=5,  # Get more results initially\n",
    ")\n",
    "\n",
    "# Add post-processing filters\n",
    "postprocessor = SimilarityPostprocessor(similarity_cutoff=0.7)\n",
    "\n",
    "# Create response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=False,\n",
    ")\n",
    "\n",
    "# Create advanced query engine\n",
    "advanced_query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    node_postprocessors=[postprocessor],\n",
    "    response_synthesizer=response_synthesizer\n",
    ")\n",
    "\n",
    "print(\"ðŸš€ Advanced query engine created!\")\n",
    "print(\"ðŸ“‹ Enhanced features:\")\n",
    "print(\"  - Similarity filtering (cutoff: 0.7)\")\n",
    "print(\"  - Higher initial retrieval (top 5)\")\n",
    "print(\"  - Post-processing for relevance\")\n",
    "print(\"  - Tree summarization for better responses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7324c615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing document-specific querying:\n",
      "============================================================\n",
      "ðŸ” Querying document: sample1.txt\n",
      "ðŸŽ¯ Created filtered query engine for: sample1.txt\n",
      "ðŸ“„ Documents included: 1\n",
      "â“ Question: What are the main types of artificial intelligence?\n",
      "--------------------------------------------------\n",
      "ðŸŽ¯ Created filtered query engine for: sample1.txt\n",
      "ðŸ“„ Documents included: 1\n",
      "â“ Question: What are the main types of artificial intelligence?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Answer:\n",
      "The main types of artificial intelligence are:\n",
      "\n",
      "1. Narrow AI (Weak AI): AI systems designed and trained for specific tasks, such as virtual assistants and recommendation algorithms.\n",
      "\n",
      "2. General AI (Strong AI): A hypothetical form of AI that can understand, learn, and apply knowledge across a wide range of tasks at a level comparable to human intelligence.\n",
      "\n",
      "3. Superintelligence: AI that exceeds human intelligence in all aspects, including creativity and social skills.\n",
      "\n",
      "============================================================\n",
      "ðŸ” Querying document: sample2.txt\n",
      "ðŸ¤– Answer:\n",
      "The main types of artificial intelligence are:\n",
      "\n",
      "1. Narrow AI (Weak AI): AI systems designed and trained for specific tasks, such as virtual assistants and recommendation algorithms.\n",
      "\n",
      "2. General AI (Strong AI): A hypothetical form of AI that can understand, learn, and apply knowledge across a wide range of tasks at a level comparable to human intelligence.\n",
      "\n",
      "3. Superintelligence: AI that exceeds human intelligence in all aspects, including creativity and social skills.\n",
      "\n",
      "============================================================\n",
      "ðŸ” Querying document: sample2.txt\n",
      "ðŸŽ¯ Created filtered query engine for: sample2.txt\n",
      "ðŸ“„ Documents included: 1\n",
      "â“ Question: What are the cloud service models?\n",
      "--------------------------------------------------\n",
      "ðŸŽ¯ Created filtered query engine for: sample2.txt\n",
      "ðŸ“„ Documents included: 1\n",
      "â“ Question: What are the cloud service models?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Answer:\n",
      "The cloud service models include:\n",
      "\n",
      "1. **Infrastructure as a Service (IaaS)**: This model provides virtualized computing resources over the internet, allowing users to rent virtual machines, storage, and networking components on a pay-as-you-go basis. Examples include Amazon Web Services (AWS) EC2, Microsoft Azure Virtual Machines, and Google Compute Engine. Benefits include complete control over operating systems and applications, scalable infrastructure, and cost-effectiveness for variable workloads.\n",
      "\n",
      "2. **Platform as a Service (PaaS)**: PaaS offers a platform for customers to develop, run, and manage applications without the complexity of building and maintaining infrastructure. Examples include Google App Engine, Microsoft Azure App Service, and Heroku. Benefits include faster application development and deployment, reduced complexity in managing infrastructure, and built-in scalability and load balancing.\n",
      "\n",
      "3. **Software as a Service (SaaS)**: This model delivers software applications over the internet on a subscription basis, allowing users to access applications through web browsers without local installation or maintenance. Examples include Salesforce, Microsoft 365, Google Workspace, and Dropbox. Benefits include no software installation or maintenance required, automatic updates and patches, and accessibility from anywhere with an internet connection.\n",
      "ðŸ” Testing Advanced Query Engine with Similarity Filtering\n",
      "============================================================\n",
      "\n",
      "1. Query: What are the main concepts in artificial intelligence?\n",
      "----------------------------------------\n",
      "ðŸ¤– Answer:\n",
      "The cloud service models include:\n",
      "\n",
      "1. **Infrastructure as a Service (IaaS)**: This model provides virtualized computing resources over the internet, allowing users to rent virtual machines, storage, and networking components on a pay-as-you-go basis. Examples include Amazon Web Services (AWS) EC2, Microsoft Azure Virtual Machines, and Google Compute Engine. Benefits include complete control over operating systems and applications, scalable infrastructure, and cost-effectiveness for variable workloads.\n",
      "\n",
      "2. **Platform as a Service (PaaS)**: PaaS offers a platform for customers to develop, run, and manage applications without the complexity of building and maintaining infrastructure. Examples include Google App Engine, Microsoft Azure App Service, and Heroku. Benefits include faster application development and deployment, reduced complexity in managing infrastructure, and built-in scalability and load balancing.\n",
      "\n",
      "3. **Software as a Service (SaaS)**: This model delivers software applications over the internet on a subscription basis, allowing users to access applications through web browsers without local installation or maintenance. Examples include Salesforce, Microsoft 365, Google Workspace, and Dropbox. Benefits include no software installation or maintenance required, automatic updates and patches, and accessibility from anywhere with an internet connection.\n",
      "ðŸ” Testing Advanced Query Engine with Similarity Filtering\n",
      "============================================================\n",
      "\n",
      "1. Query: What are the main concepts in artificial intelligence?\n",
      "----------------------------------------\n",
      "ðŸ¤– Response: Empty Response\n",
      "\n",
      "\n",
      "2. Query: How does cloud computing work?\n",
      "----------------------------------------\n",
      "ðŸ¤– Response: Empty Response\n",
      "\n",
      "\n",
      "2. Query: How does cloud computing work?\n",
      "----------------------------------------\n",
      "ðŸ¤– Response: Empty Response\n",
      "\n",
      "\n",
      "3. Query: What are the benefits of machine learning?\n",
      "----------------------------------------\n",
      "ðŸ¤– Response: Empty Response\n",
      "\n",
      "\n",
      "3. Query: What are the benefits of machine learning?\n",
      "----------------------------------------\n",
      "ðŸ¤– Response: Empty Response\n",
      "\n",
      "\n",
      "4. Query: Explain containerization in cloud computing\n",
      "----------------------------------------\n",
      "ðŸ¤– Response: Empty Response\n",
      "\n",
      "\n",
      "4. Query: Explain containerization in cloud computing\n",
      "----------------------------------------\n",
      "ðŸ¤– Response: Empty Response\n",
      "\n",
      "âœ… Advanced query testing completed!\n",
      "ðŸ¤– Response: Empty Response\n",
      "\n",
      "âœ… Advanced query testing completed!\n"
     ]
    }
   ],
   "source": [
    "# Create a custom query engine that can filter by document source\n",
    "def create_document_specific_query_engine(document_filter=None):\n",
    "    \"\"\"\n",
    "    Create a query engine that can filter by specific documents\n",
    "    \n",
    "    Args:\n",
    "        document_filter: String to match document names (e.g., \"sample1.txt\")\n",
    "    \"\"\"\n",
    "    \n",
    "    if document_filter:\n",
    "        # Filter nodes by document\n",
    "        filtered_nodes = [\n",
    "            node for node in index.docstore.docs.values() \n",
    "            if document_filter.lower() in node.metadata.get('file_name', '').lower()\n",
    "        ]\n",
    "        \n",
    "        if not filtered_nodes:\n",
    "            print(f\"âš ï¸ No documents found matching filter: {document_filter}\")\n",
    "            return None\n",
    "            \n",
    "        # Create a new index with filtered nodes\n",
    "        from llama_index.core import DocumentSummaryIndex\n",
    "        filtered_docs = [\n",
    "            doc for doc in documents \n",
    "            if document_filter.lower() in doc.metadata.get('file_name', '').lower()\n",
    "        ]\n",
    "        \n",
    "        if filtered_docs:\n",
    "            filtered_index = VectorStoreIndex.from_documents(filtered_docs)\n",
    "            query_engine = filtered_index.as_query_engine(similarity_top_k=3)\n",
    "            print(f\"ðŸŽ¯ Created filtered query engine for: {document_filter}\")\n",
    "            print(f\"ðŸ“„ Documents included: {len(filtered_docs)}\")\n",
    "            return query_engine\n",
    "    \n",
    "    return advanced_query_engine\n",
    "\n",
    "# Test document-specific querying\n",
    "def query_specific_document(question, document_filter=None):\n",
    "    \"\"\"Query a specific document or all documents\"\"\"\n",
    "    \n",
    "    if document_filter:\n",
    "        print(f\"ðŸ” Querying document: {document_filter}\")\n",
    "        engine = create_document_specific_query_engine(document_filter)\n",
    "        if not engine:\n",
    "            return None\n",
    "    else:\n",
    "        print(\"ðŸ” Querying all documents\")\n",
    "        engine = advanced_query_engine\n",
    "    \n",
    "    print(f\"â“ Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    response = engine.query(question)\n",
    "    print(\"ðŸ¤– Answer:\")\n",
    "    print(response.response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example queries\n",
    "print(\"Testing document-specific querying:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Query about AI from the AI document\n",
    "query_specific_document(\n",
    "    \"What are the main types of artificial intelligence?\", \n",
    "    \"sample1.txt\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Query about cloud computing from the cloud document  \n",
    "query_specific_document(\n",
    "    \"What are the cloud service models?\",\n",
    "    \"sample2.txt\"\n",
    ")\n",
    "\n",
    "# Test advanced query engine with similarity filtering\n",
    "test_queries = [\n",
    "    \"What are the main concepts in artificial intelligence?\",\n",
    "    \"How does cloud computing work?\",\n",
    "    \"What are the benefits of machine learning?\",\n",
    "    \"Explain containerization in cloud computing\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ” Testing Advanced Query Engine with Similarity Filtering\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n{i}. Query: {query}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Query with advanced engine\n",
    "    response = advanced_query_engine.query(query)\n",
    "    print(f\"ðŸ¤– Response: {response.response}\")\n",
    "    \n",
    "    # Show retrieved nodes information\n",
    "    if hasattr(response, 'source_nodes') and response.source_nodes:\n",
    "        print(f\"ðŸ“š Sources used: {len(response.source_nodes)} documents\")\n",
    "        for j, node in enumerate(response.source_nodes[:2]):  # Show first 2 sources\n",
    "            if hasattr(node, 'score'):\n",
    "                print(f\"   - Source {j+1} (similarity: {node.score:.3f})\")\n",
    "            else:\n",
    "                print(f\"   - Source {j+1}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"âœ… Advanced query testing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0c8207",
   "metadata": {},
   "source": [
    "## 6. Conversational Document Agent\n",
    "\n",
    "Let's create a conversational agent that can maintain context across multiple queries about our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa156cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ Conversational Document Agent created!\n",
      "ðŸŽ¯ Features:\n",
      "  - Maintains conversation context\n",
      "  - Source attribution\n",
      "  - Memory management\n",
      "  - Multi-turn conversations\n"
     ]
    }
   ],
   "source": [
    "# Create a conversational document agent\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "class ConversationalDocumentAgent:\n",
    "    def __init__(self, index, memory_limit=10):\n",
    "        self.index = index\n",
    "        self.memory = ChatMemoryBuffer.from_defaults(token_limit=3000)\n",
    "        self.conversation_history = []\n",
    "        self.memory_limit = memory_limit\n",
    "        \n",
    "        # Create chat engine with memory\n",
    "        self.chat_engine = index.as_chat_engine(\n",
    "            chat_mode=\"context\",\n",
    "            memory=self.memory,\n",
    "            similarity_top_k=3,\n",
    "            system_prompt=(\n",
    "                \"You are a helpful document analysis assistant. \"\n",
    "                \"Answer questions based on the provided document content. \"\n",
    "                \"Always cite the source document when possible. \"\n",
    "                \"If information is not in the documents, clearly state that. \"\n",
    "                \"Maintain conversation context and refer to previous answers when relevant.\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def query(self, question):\n",
    "        \"\"\"Process a query with conversation context\"\"\"\n",
    "        print(f\"ðŸ—£ï¸ User: {question}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Get response from chat engine\n",
    "        response = self.chat_engine.chat(question)\n",
    "        \n",
    "        print(\"ðŸ¤– Assistant:\")\n",
    "        print(response.response)\n",
    "        \n",
    "        # Add to conversation history\n",
    "        self.conversation_history.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": response.response,\n",
    "            \"sources\": len(response.source_nodes) if hasattr(response, 'source_nodes') else 0\n",
    "        })\n",
    "        \n",
    "        # Keep history manageable\n",
    "        if len(self.conversation_history) > self.memory_limit:\n",
    "            self.conversation_history = self.conversation_history[-self.memory_limit:]\n",
    "        \n",
    "        # Show sources if available\n",
    "        if hasattr(response, 'source_nodes') and response.source_nodes:\n",
    "            print(f\"\\nðŸ“š Sources ({len(response.source_nodes)} chunks):\")\n",
    "            for i, node in enumerate(response.source_nodes, 1):\n",
    "                doc_name = node.metadata.get('file_name', 'Unknown')\n",
    "                print(f\"  {i}. {doc_name} (Score: {node.score:.3f})\")\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def get_conversation_summary(self):\n",
    "        \"\"\"Get a summary of the conversation\"\"\"\n",
    "        return {\n",
    "            \"total_questions\": len(self.conversation_history),\n",
    "            \"questions\": [item[\"question\"] for item in self.conversation_history]\n",
    "        }\n",
    "    \n",
    "    def reset_conversation(self):\n",
    "        \"\"\"Reset the conversation history\"\"\"\n",
    "        self.conversation_history = []\n",
    "        self.memory.reset()\n",
    "        print(\"ðŸ”„ Conversation history reset\")\n",
    "\n",
    "# Create the conversational agent\n",
    "agent = ConversationalDocumentAgent(index)\n",
    "print(\"ðŸ’¬ Conversational Document Agent created!\")\n",
    "print(\"ðŸŽ¯ Features:\")\n",
    "print(\"  - Maintains conversation context\")\n",
    "print(\"  - Source attribution\")\n",
    "print(\"  - Memory management\")\n",
    "print(\"  - Multi-turn conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1787881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ­ Starting multi-turn conversation:\n",
      "============================================================\n",
      "\n",
      "ðŸ”„ Turn 1:\n",
      "ðŸ—£ï¸ User: What is artificial intelligence?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Assistant:\n",
      "Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. It encompasses any machine that exhibits traits associated with a human mind, such as learning and problem-solving. The field of AI can be broadly categorized into:\n",
      "\n",
      "1. **Narrow AI (Weak AI)**: AI systems designed and trained for a specific task, such as virtual assistants (e.g., Siri, Alexa), recommendation algorithms, and image recognition systems.\n",
      "\n",
      "2. **General AI (Strong AI)**: A hypothetical form of AI that would possess the ability to understand, learn, and apply knowledge across a wide range of tasks at a level equal to human intelligence.\n",
      "\n",
      "3. **Superintelligence**: AI that surpasses human intelligence in all aspects, including creativity, general wisdom, and social skills.\n",
      "\n",
      "This definition and categorization of AI are derived from the document titled \"Artificial Intelligence and Machine Learning: A Comprehensive Overview.\"\n",
      "\n",
      "ðŸ“š Sources (3 chunks):\n",
      "  1. sample1.txt (Score: 0.446)\n",
      "  2. sample2.txt (Score: 0.247)\n",
      "  3. sample2.txt (Score: 0.236)\n",
      "\n",
      "â³ (continuing conversation...)\n",
      "\n",
      "ðŸ”„ Turn 2:\n",
      "ðŸ—£ï¸ User: What are the main types you mentioned?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Assistant:\n",
      "Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. It encompasses any machine that exhibits traits associated with a human mind, such as learning and problem-solving. The field of AI can be broadly categorized into:\n",
      "\n",
      "1. **Narrow AI (Weak AI)**: AI systems designed and trained for a specific task, such as virtual assistants (e.g., Siri, Alexa), recommendation algorithms, and image recognition systems.\n",
      "\n",
      "2. **General AI (Strong AI)**: A hypothetical form of AI that would possess the ability to understand, learn, and apply knowledge across a wide range of tasks at a level equal to human intelligence.\n",
      "\n",
      "3. **Superintelligence**: AI that surpasses human intelligence in all aspects, including creativity, general wisdom, and social skills.\n",
      "\n",
      "This definition and categorization of AI are derived from the document titled \"Artificial Intelligence and Machine Learning: A Comprehensive Overview.\"\n",
      "\n",
      "ðŸ“š Sources (3 chunks):\n",
      "  1. sample1.txt (Score: 0.446)\n",
      "  2. sample2.txt (Score: 0.247)\n",
      "  3. sample2.txt (Score: 0.236)\n",
      "\n",
      "â³ (continuing conversation...)\n",
      "\n",
      "ðŸ”„ Turn 2:\n",
      "ðŸ—£ï¸ User: What are the main types you mentioned?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Assistant:\n",
      "The main types of Artificial Intelligence (AI) mentioned in the document are:\n",
      "\n",
      "1. **Narrow AI (Weak AI)**: AI systems that are designed and trained for a specific task. Examples include virtual assistants like Siri or Alexa, recommendation algorithms, and image recognition systems.\n",
      "\n",
      "2. **General AI (Strong AI)**: A hypothetical form of AI that possesses the ability to understand, learn, and apply knowledge across a wide range of tasks at a level equal to human intelligence.\n",
      "\n",
      "3. **Superintelligence**: AI that surpasses human intelligence in all aspects, including creativity, general wisdom, and social skills.\n",
      "\n",
      "These categories help to understand the different capabilities and potential of AI systems. This information is sourced from the document titled \"Artificial Intelligence and Machine Learning: A Comprehensive Overview.\"\n",
      "\n",
      "ðŸ“š Sources (3 chunks):\n",
      "  1. sample1.txt (Score: 0.183)\n",
      "  2. sample2.txt (Score: 0.159)\n",
      "  3. sample2.txt (Score: 0.156)\n",
      "\n",
      "â³ (continuing conversation...)\n",
      "\n",
      "ðŸ”„ Turn 3:\n",
      "ðŸ—£ï¸ User: How does this relate to machine learning?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Assistant:\n",
      "The main types of Artificial Intelligence (AI) mentioned in the document are:\n",
      "\n",
      "1. **Narrow AI (Weak AI)**: AI systems that are designed and trained for a specific task. Examples include virtual assistants like Siri or Alexa, recommendation algorithms, and image recognition systems.\n",
      "\n",
      "2. **General AI (Strong AI)**: A hypothetical form of AI that possesses the ability to understand, learn, and apply knowledge across a wide range of tasks at a level equal to human intelligence.\n",
      "\n",
      "3. **Superintelligence**: AI that surpasses human intelligence in all aspects, including creativity, general wisdom, and social skills.\n",
      "\n",
      "These categories help to understand the different capabilities and potential of AI systems. This information is sourced from the document titled \"Artificial Intelligence and Machine Learning: A Comprehensive Overview.\"\n",
      "\n",
      "ðŸ“š Sources (3 chunks):\n",
      "  1. sample1.txt (Score: 0.183)\n",
      "  2. sample2.txt (Score: 0.159)\n",
      "  3. sample2.txt (Score: 0.156)\n",
      "\n",
      "â³ (continuing conversation...)\n",
      "\n",
      "ðŸ”„ Turn 3:\n",
      "ðŸ—£ï¸ User: How does this relate to machine learning?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Assistant:\n",
      "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that focuses on enabling computers to learn and improve from experience without being explicitly programmed. While AI encompasses a broader range of technologies and applications that simulate human intelligence, ML specifically deals with the development of algorithms that can analyze data, learn from it, and make predictions or decisions based on that learning.\n",
      "\n",
      "Hereâ€™s how they relate:\n",
      "\n",
      "- **AI as an Umbrella**: AI is the overarching field that includes various technologies, including machine learning. AI systems can utilize machine learning techniques to enhance their capabilities.\n",
      "\n",
      "- **Learning from Data**: Machine learning algorithms build mathematical models based on training data, allowing them to identify patterns and make predictions. This is a key aspect of how AI systems can simulate human-like learning and decision-making.\n",
      "\n",
      "- **Types of Machine Learning**: The document outlines three main types of machine learning:\n",
      "  1. **Supervised Learning**: Learning from labeled training data to make predictions on new, unseen data.\n",
      "  2. **Unsupervised Learning**: Finding hidden patterns in data without labeled examples.\n",
      "  3. **Reinforcement Learning**: Learning through interaction with an environment, receiving rewards or penalties based on actions.\n",
      "\n",
      "In summary, while AI refers to the broader concept of machines simulating human intelligence, machine learning is a specific approach within AI that focuses on the ability of machines to learn from data. This relationship is detailed in the document titled \"Artificial Intelligence and Machine Learning: A Comprehensive Overview.\"\n",
      "\n",
      "ðŸ“š Sources (3 chunks):\n",
      "  1. sample1.txt (Score: 0.430)\n",
      "  2. sample2.txt (Score: 0.283)\n",
      "  3. sample2.txt (Score: 0.239)\n",
      "\n",
      "â³ (continuing conversation...)\n",
      "\n",
      "ðŸ”„ Turn 4:\n",
      "ðŸ—£ï¸ User: Now tell me about cloud computing\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Assistant:\n",
      "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that focuses on enabling computers to learn and improve from experience without being explicitly programmed. While AI encompasses a broader range of technologies and applications that simulate human intelligence, ML specifically deals with the development of algorithms that can analyze data, learn from it, and make predictions or decisions based on that learning.\n",
      "\n",
      "Hereâ€™s how they relate:\n",
      "\n",
      "- **AI as an Umbrella**: AI is the overarching field that includes various technologies, including machine learning. AI systems can utilize machine learning techniques to enhance their capabilities.\n",
      "\n",
      "- **Learning from Data**: Machine learning algorithms build mathematical models based on training data, allowing them to identify patterns and make predictions. This is a key aspect of how AI systems can simulate human-like learning and decision-making.\n",
      "\n",
      "- **Types of Machine Learning**: The document outlines three main types of machine learning:\n",
      "  1. **Supervised Learning**: Learning from labeled training data to make predictions on new, unseen data.\n",
      "  2. **Unsupervised Learning**: Finding hidden patterns in data without labeled examples.\n",
      "  3. **Reinforcement Learning**: Learning through interaction with an environment, receiving rewards or penalties based on actions.\n",
      "\n",
      "In summary, while AI refers to the broader concept of machines simulating human intelligence, machine learning is a specific approach within AI that focuses on the ability of machines to learn from data. This relationship is detailed in the document titled \"Artificial Intelligence and Machine Learning: A Comprehensive Overview.\"\n",
      "\n",
      "ðŸ“š Sources (3 chunks):\n",
      "  1. sample1.txt (Score: 0.430)\n",
      "  2. sample2.txt (Score: 0.283)\n",
      "  3. sample2.txt (Score: 0.239)\n",
      "\n",
      "â³ (continuing conversation...)\n",
      "\n",
      "ðŸ”„ Turn 4:\n",
      "ðŸ—£ï¸ User: Now tell me about cloud computing\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Assistant:\n",
      "Cloud computing is the delivery of computing servicesâ€”including servers, storage, databases, networking, software, analytics, and intelligenceâ€”over the internet (\"the cloud\"). It enables businesses and individuals to access, store, and process data on-demand, providing unprecedented scalability, flexibility, and cost-effectiveness in IT operations.\n",
      "\n",
      "### Key Aspects of Cloud Computing:\n",
      "\n",
      "1. **Essential Characteristics**:\n",
      "   - **On-demand self-service**: Users can provision computing capabilities automatically without requiring human interaction with service providers.\n",
      "   - **Broad network access**: Capabilities are available over the network and accessed through standard mechanisms.\n",
      "   - **Resource pooling**: Computing resources are pooled to serve multiple consumers using a multi-tenant model.\n",
      "   - **Rapid elasticity**: Capabilities can be elastically provisioned and released to scale rapidly.\n",
      "   - **Measured service**: Cloud systems automatically control and optimize resource use by leveraging metering capabilities.\n",
      "\n",
      "2. **Cloud Service Models**:\n",
      "   - **Infrastructure as a Service (IaaS)**: Provides virtualized computing resources over the internet. Users can rent virtual machines, storage, and networking components on a pay-as-you-go basis (e.g., AWS EC2, Microsoft Azure).\n",
      "   - **Platform as a Service (PaaS)**: Offers a platform for customers to develop, run, and manage applications without dealing with the complexity of building and maintaining infrastructure (e.g., Google App Engine).\n",
      "   - **Software as a Service (SaaS)**: Delivers software applications over the internet on a subscription basis, accessible through web browsers without local installation (e.g., Salesforce, Microsoft 365).\n",
      "\n",
      "3. **Cloud Deployment Models**:\n",
      "   - **Public Cloud**: Services are provided over the public internet and available to anyone. Resources are owned and operated by third-party providers.\n",
      "   - **Private Cloud**: Cloud infrastructure is provisioned for exclusive use by a single organization, offering greater control and security.\n",
      "   - **Hybrid Cloud**: Combines public and private clouds, allowing data and applications to be shared between them for greater flexibility.\n",
      "   - **Multi-Cloud**: Uses multiple cloud services from different providers to avoid vendor lock-in and optimize costs.\n",
      "\n",
      "4. **Benefits of Cloud Computing**:\n",
      "   - **Cost Efficiency**: Reduced capital expenditure and operational costs through pay-as-you-use pricing models.\n",
      "   - **Scalability and Flexibility**: Rapid scaling based on demand and access to the latest technologies.\n",
      "   - **Reliability and Availability**: High uptime guarantees and built-in redundancy.\n",
      "   - **Innovation and Speed**: Faster time-to-market for applications and access to cutting-edge technologies.\n",
      "\n",
      "5. **Challenges and Considerations**:\n",
      "   - **Security and Privacy**: Concerns about data breaches and compliance with regulations.\n",
      "   - **Vendor Lock-in**: Difficulty in migrating between cloud providers.\n",
      "   - **Performance and Latency**: Network dependency and potential performance bottlenecks.\n",
      "   - **Cost Management**: Unexpected charges and complex pricing models.\n",
      "\n",
      "6. **Trends in Cloud Computing**:\n",
      "   - **Edge Computing**: Processing data closer to where it's generated.\n",
      "   - **Serverless Computing**: Running applications without managing servers.\n",
      "   - **Container Orchestration**: Managing containerized applications at scale.\n",
      "   - **AI and Machine Learning Integration**: Cloud providers offering AI/ML services as managed offerings.\n",
      "\n",
      "### Conclusion\n",
      "Cloud computing has fundamentally transformed how organizations approach IT infrastructure and application deployment, enabling faster innovation and more efficient scaling. Understanding the various service and deployment models is crucial for successful cloud adoption. This information is derived from the document titled \"Cloud Computing: Transforming Modern Business Infrastructure.\"\n",
      "\n",
      "ðŸ“š Sources (3 chunks):\n",
      "  1. sample2.txt (Score: 0.528)\n",
      "  2. sample2.txt (Score: 0.504)\n",
      "  3. sample1.txt (Score: 0.246)\n",
      "\n",
      "â³ (continuing conversation...)\n",
      "\n",
      "ðŸ”„ Turn 5:\n",
      "ðŸ—£ï¸ User: What are the advantages compared to traditional IT infrastructure?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Assistant:\n",
      "Cloud computing is the delivery of computing servicesâ€”including servers, storage, databases, networking, software, analytics, and intelligenceâ€”over the internet (\"the cloud\"). It enables businesses and individuals to access, store, and process data on-demand, providing unprecedented scalability, flexibility, and cost-effectiveness in IT operations.\n",
      "\n",
      "### Key Aspects of Cloud Computing:\n",
      "\n",
      "1. **Essential Characteristics**:\n",
      "   - **On-demand self-service**: Users can provision computing capabilities automatically without requiring human interaction with service providers.\n",
      "   - **Broad network access**: Capabilities are available over the network and accessed through standard mechanisms.\n",
      "   - **Resource pooling**: Computing resources are pooled to serve multiple consumers using a multi-tenant model.\n",
      "   - **Rapid elasticity**: Capabilities can be elastically provisioned and released to scale rapidly.\n",
      "   - **Measured service**: Cloud systems automatically control and optimize resource use by leveraging metering capabilities.\n",
      "\n",
      "2. **Cloud Service Models**:\n",
      "   - **Infrastructure as a Service (IaaS)**: Provides virtualized computing resources over the internet. Users can rent virtual machines, storage, and networking components on a pay-as-you-go basis (e.g., AWS EC2, Microsoft Azure).\n",
      "   - **Platform as a Service (PaaS)**: Offers a platform for customers to develop, run, and manage applications without dealing with the complexity of building and maintaining infrastructure (e.g., Google App Engine).\n",
      "   - **Software as a Service (SaaS)**: Delivers software applications over the internet on a subscription basis, accessible through web browsers without local installation (e.g., Salesforce, Microsoft 365).\n",
      "\n",
      "3. **Cloud Deployment Models**:\n",
      "   - **Public Cloud**: Services are provided over the public internet and available to anyone. Resources are owned and operated by third-party providers.\n",
      "   - **Private Cloud**: Cloud infrastructure is provisioned for exclusive use by a single organization, offering greater control and security.\n",
      "   - **Hybrid Cloud**: Combines public and private clouds, allowing data and applications to be shared between them for greater flexibility.\n",
      "   - **Multi-Cloud**: Uses multiple cloud services from different providers to avoid vendor lock-in and optimize costs.\n",
      "\n",
      "4. **Benefits of Cloud Computing**:\n",
      "   - **Cost Efficiency**: Reduced capital expenditure and operational costs through pay-as-you-use pricing models.\n",
      "   - **Scalability and Flexibility**: Rapid scaling based on demand and access to the latest technologies.\n",
      "   - **Reliability and Availability**: High uptime guarantees and built-in redundancy.\n",
      "   - **Innovation and Speed**: Faster time-to-market for applications and access to cutting-edge technologies.\n",
      "\n",
      "5. **Challenges and Considerations**:\n",
      "   - **Security and Privacy**: Concerns about data breaches and compliance with regulations.\n",
      "   - **Vendor Lock-in**: Difficulty in migrating between cloud providers.\n",
      "   - **Performance and Latency**: Network dependency and potential performance bottlenecks.\n",
      "   - **Cost Management**: Unexpected charges and complex pricing models.\n",
      "\n",
      "6. **Trends in Cloud Computing**:\n",
      "   - **Edge Computing**: Processing data closer to where it's generated.\n",
      "   - **Serverless Computing**: Running applications without managing servers.\n",
      "   - **Container Orchestration**: Managing containerized applications at scale.\n",
      "   - **AI and Machine Learning Integration**: Cloud providers offering AI/ML services as managed offerings.\n",
      "\n",
      "### Conclusion\n",
      "Cloud computing has fundamentally transformed how organizations approach IT infrastructure and application deployment, enabling faster innovation and more efficient scaling. Understanding the various service and deployment models is crucial for successful cloud adoption. This information is derived from the document titled \"Cloud Computing: Transforming Modern Business Infrastructure.\"\n",
      "\n",
      "ðŸ“š Sources (3 chunks):\n",
      "  1. sample2.txt (Score: 0.528)\n",
      "  2. sample2.txt (Score: 0.504)\n",
      "  3. sample1.txt (Score: 0.246)\n",
      "\n",
      "â³ (continuing conversation...)\n",
      "\n",
      "ðŸ”„ Turn 5:\n",
      "ðŸ—£ï¸ User: What are the advantages compared to traditional IT infrastructure?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Assistant:\n",
      "Cloud computing offers several advantages compared to traditional IT infrastructure, including:\n",
      "\n",
      "1. **Cost Efficiency**:\n",
      "   - **Reduced Capital Expenditure**: Organizations can avoid significant upfront investments in hardware and infrastructure, as cloud services typically operate on a pay-as-you-go model.\n",
      "   - **Lower Operational Costs**: Cloud providers leverage economies of scale, which can lead to lower operational costs for users.\n",
      "\n",
      "2. **Scalability and Flexibility**:\n",
      "   - **Rapid Scaling**: Cloud resources can be quickly scaled up or down based on demand, allowing businesses to respond to changing needs without the delays associated with purchasing and installing new hardware.\n",
      "   - **Access to Latest Technologies**: Users can easily access the latest technologies and services without needing to upgrade their own infrastructure.\n",
      "\n",
      "3. **Reliability and Availability**:\n",
      "   - **High Uptime Guarantees**: Cloud providers often offer high uptime guarantees (99.9% or higher), ensuring that services are available when needed.\n",
      "   - **Built-in Redundancy and Disaster Recovery**: Cloud services typically include redundancy and disaster recovery options, enhancing data protection and availability.\n",
      "\n",
      "4. **Innovation and Speed**:\n",
      "   - **Faster Time-to-Market**: Organizations can deploy applications and services more quickly, allowing them to innovate and respond to market demands faster.\n",
      "   - **Focus on Core Business**: By outsourcing IT infrastructure management to cloud providers, organizations can focus more on their core business activities rather than IT maintenance.\n",
      "\n",
      "5. **Global Reach and Availability**:\n",
      "   - **Access from Anywhere**: Cloud services can be accessed from any location with an internet connection, enabling remote work and collaboration.\n",
      "   - **Geographic Redundancy**: Many cloud providers have data centers in multiple locations, which can enhance performance and reliability.\n",
      "\n",
      "6. **Enhanced Security Features**:\n",
      "   - **Professional Management and Monitoring**: Cloud providers often have dedicated teams for security management, monitoring, and compliance, which can be more effective than in-house efforts.\n",
      "   - **Advanced Security Technologies**: Many cloud services include built-in security features such as encryption, identity management, and access controls.\n",
      "\n",
      "These advantages make cloud computing an attractive option for organizations looking to improve their IT operations and adapt to the rapidly changing technological landscape. This information is sourced from the document titled \"Cloud Computing: Transforming Modern Business Infrastructure.\"\n",
      "\n",
      "ðŸ“š Sources (3 chunks):\n",
      "  1. sample2.txt (Score: 0.475)\n",
      "  2. sample2.txt (Score: 0.435)\n",
      "  3. sample1.txt (Score: 0.216)\n",
      "\n",
      "â³ (continuing conversation...)\n",
      "\n",
      "ðŸ”„ Turn 6:\n",
      "ðŸ—£ï¸ User: Which service model would be best for a startup?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Assistant:\n",
      "Cloud computing offers several advantages compared to traditional IT infrastructure, including:\n",
      "\n",
      "1. **Cost Efficiency**:\n",
      "   - **Reduced Capital Expenditure**: Organizations can avoid significant upfront investments in hardware and infrastructure, as cloud services typically operate on a pay-as-you-go model.\n",
      "   - **Lower Operational Costs**: Cloud providers leverage economies of scale, which can lead to lower operational costs for users.\n",
      "\n",
      "2. **Scalability and Flexibility**:\n",
      "   - **Rapid Scaling**: Cloud resources can be quickly scaled up or down based on demand, allowing businesses to respond to changing needs without the delays associated with purchasing and installing new hardware.\n",
      "   - **Access to Latest Technologies**: Users can easily access the latest technologies and services without needing to upgrade their own infrastructure.\n",
      "\n",
      "3. **Reliability and Availability**:\n",
      "   - **High Uptime Guarantees**: Cloud providers often offer high uptime guarantees (99.9% or higher), ensuring that services are available when needed.\n",
      "   - **Built-in Redundancy and Disaster Recovery**: Cloud services typically include redundancy and disaster recovery options, enhancing data protection and availability.\n",
      "\n",
      "4. **Innovation and Speed**:\n",
      "   - **Faster Time-to-Market**: Organizations can deploy applications and services more quickly, allowing them to innovate and respond to market demands faster.\n",
      "   - **Focus on Core Business**: By outsourcing IT infrastructure management to cloud providers, organizations can focus more on their core business activities rather than IT maintenance.\n",
      "\n",
      "5. **Global Reach and Availability**:\n",
      "   - **Access from Anywhere**: Cloud services can be accessed from any location with an internet connection, enabling remote work and collaboration.\n",
      "   - **Geographic Redundancy**: Many cloud providers have data centers in multiple locations, which can enhance performance and reliability.\n",
      "\n",
      "6. **Enhanced Security Features**:\n",
      "   - **Professional Management and Monitoring**: Cloud providers often have dedicated teams for security management, monitoring, and compliance, which can be more effective than in-house efforts.\n",
      "   - **Advanced Security Technologies**: Many cloud services include built-in security features such as encryption, identity management, and access controls.\n",
      "\n",
      "These advantages make cloud computing an attractive option for organizations looking to improve their IT operations and adapt to the rapidly changing technological landscape. This information is sourced from the document titled \"Cloud Computing: Transforming Modern Business Infrastructure.\"\n",
      "\n",
      "ðŸ“š Sources (3 chunks):\n",
      "  1. sample2.txt (Score: 0.475)\n",
      "  2. sample2.txt (Score: 0.435)\n",
      "  3. sample1.txt (Score: 0.216)\n",
      "\n",
      "â³ (continuing conversation...)\n",
      "\n",
      "ðŸ”„ Turn 6:\n",
      "ðŸ—£ï¸ User: Which service model would be best for a startup?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Assistant:\n",
      "The best cloud service model for a startup often depends on the specific needs, goals, and technical expertise of the organization. However, here are some considerations for each service model that can help determine the most suitable option:\n",
      "\n",
      "1. **Infrastructure as a Service (IaaS)**:\n",
      "   - **Best For**: Startups that require complete control over their infrastructure and want to manage their own operating systems and applications.\n",
      "   - **Advantages**: \n",
      "     - Flexibility to configure and customize resources.\n",
      "     - Scalable infrastructure that can grow with the business.\n",
      "     - Cost-effective for variable workloads, as you only pay for what you use.\n",
      "   - **Examples**: Amazon Web Services (AWS) EC2, Microsoft Azure Virtual Machines.\n",
      "\n",
      "2. **Platform as a Service (PaaS)**:\n",
      "   - **Best For**: Startups focused on application development without the complexity of managing underlying infrastructure.\n",
      "   - **Advantages**:\n",
      "     - Faster application development and deployment, allowing startups to bring products to market quickly.\n",
      "     - Built-in scalability and load balancing, which can be beneficial as user demand grows.\n",
      "     - Reduced complexity in managing infrastructure, enabling teams to focus on coding and innovation.\n",
      "   - **Examples**: Google App Engine, Microsoft Azure App Service, Heroku.\n",
      "\n",
      "3. **Software as a Service (SaaS)**:\n",
      "   - **Best For**: Startups that need ready-to-use software applications without the need for installation or maintenance.\n",
      "   - **Advantages**:\n",
      "     - No software installation or maintenance required, which can save time and resources.\n",
      "     - Automatic updates and patches, ensuring access to the latest features and security.\n",
      "     - Accessibility from anywhere with an internet connection, facilitating remote work.\n",
      "   - **Examples**: Salesforce, Microsoft 365, Google Workspace.\n",
      "\n",
      "### Recommendation:\n",
      "For many startups, **Platform as a Service (PaaS)** is often the most suitable option, as it allows for rapid development and deployment of applications while minimizing the need for infrastructure management. This enables startups to focus on building their products and scaling their operations without getting bogged down by IT complexities.\n",
      "\n",
      "However, if a startup has specific infrastructure needs or requires more control, **IaaS** could be a better fit. Conversely, if the startup is looking for specific software solutions to support their operations, **SaaS** might be the way to go.\n",
      "\n",
      "Ultimately, the choice should align with the startup's business model, technical capabilities, and growth plans. This information is derived from the document titled \"Cloud Computing: Transforming Modern Business Infrastructure.\"\n",
      "\n",
      "ðŸ“š Sources (3 chunks):\n",
      "  1. sample2.txt (Score: 0.406)\n",
      "  2. sample2.txt (Score: 0.377)\n",
      "  3. sample1.txt (Score: 0.172)\n",
      "\n",
      "ðŸ“Š Conversation summary: {'total_questions': 6, 'questions': ['What is artificial intelligence?', 'What are the main types you mentioned?', 'How does this relate to machine learning?', 'Now tell me about cloud computing', 'What are the advantages compared to traditional IT infrastructure?', 'Which service model would be best for a startup?']}\n",
      "ðŸ¤– Assistant:\n",
      "The best cloud service model for a startup often depends on the specific needs, goals, and technical expertise of the organization. However, here are some considerations for each service model that can help determine the most suitable option:\n",
      "\n",
      "1. **Infrastructure as a Service (IaaS)**:\n",
      "   - **Best For**: Startups that require complete control over their infrastructure and want to manage their own operating systems and applications.\n",
      "   - **Advantages**: \n",
      "     - Flexibility to configure and customize resources.\n",
      "     - Scalable infrastructure that can grow with the business.\n",
      "     - Cost-effective for variable workloads, as you only pay for what you use.\n",
      "   - **Examples**: Amazon Web Services (AWS) EC2, Microsoft Azure Virtual Machines.\n",
      "\n",
      "2. **Platform as a Service (PaaS)**:\n",
      "   - **Best For**: Startups focused on application development without the complexity of managing underlying infrastructure.\n",
      "   - **Advantages**:\n",
      "     - Faster application development and deployment, allowing startups to bring products to market quickly.\n",
      "     - Built-in scalability and load balancing, which can be beneficial as user demand grows.\n",
      "     - Reduced complexity in managing infrastructure, enabling teams to focus on coding and innovation.\n",
      "   - **Examples**: Google App Engine, Microsoft Azure App Service, Heroku.\n",
      "\n",
      "3. **Software as a Service (SaaS)**:\n",
      "   - **Best For**: Startups that need ready-to-use software applications without the need for installation or maintenance.\n",
      "   - **Advantages**:\n",
      "     - No software installation or maintenance required, which can save time and resources.\n",
      "     - Automatic updates and patches, ensuring access to the latest features and security.\n",
      "     - Accessibility from anywhere with an internet connection, facilitating remote work.\n",
      "   - **Examples**: Salesforce, Microsoft 365, Google Workspace.\n",
      "\n",
      "### Recommendation:\n",
      "For many startups, **Platform as a Service (PaaS)** is often the most suitable option, as it allows for rapid development and deployment of applications while minimizing the need for infrastructure management. This enables startups to focus on building their products and scaling their operations without getting bogged down by IT complexities.\n",
      "\n",
      "However, if a startup has specific infrastructure needs or requires more control, **IaaS** could be a better fit. Conversely, if the startup is looking for specific software solutions to support their operations, **SaaS** might be the way to go.\n",
      "\n",
      "Ultimately, the choice should align with the startup's business model, technical capabilities, and growth plans. This information is derived from the document titled \"Cloud Computing: Transforming Modern Business Infrastructure.\"\n",
      "\n",
      "ðŸ“š Sources (3 chunks):\n",
      "  1. sample2.txt (Score: 0.406)\n",
      "  2. sample2.txt (Score: 0.377)\n",
      "  3. sample1.txt (Score: 0.172)\n",
      "\n",
      "ðŸ“Š Conversation summary: {'total_questions': 6, 'questions': ['What is artificial intelligence?', 'What are the main types you mentioned?', 'How does this relate to machine learning?', 'Now tell me about cloud computing', 'What are the advantages compared to traditional IT infrastructure?', 'Which service model would be best for a startup?']}\n"
     ]
    }
   ],
   "source": [
    "# Test the conversational agent with a multi-turn conversation\n",
    "conversation_queries = [\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"What are the main types you mentioned?\",\n",
    "    \"How does this relate to machine learning?\",\n",
    "    \"Now tell me about cloud computing\",\n",
    "    \"What are the advantages compared to traditional IT infrastructure?\",\n",
    "    \"Which service model would be best for a startup?\"\n",
    "]\n",
    "\n",
    "print(\"ðŸŽ­ Starting multi-turn conversation:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, query in enumerate(conversation_queries, 1):\n",
    "    print(f\"\\nðŸ”„ Turn {i}:\")\n",
    "    agent.query(query)\n",
    "    \n",
    "    if i < len(conversation_queries):\n",
    "        print(\"\\nâ³ (continuing conversation...)\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Conversation summary: {agent.get_conversation_summary()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7fe49e",
   "metadata": {},
   "source": [
    "## 7. Advanced Features and Document Analysis\n",
    "\n",
    "Let's explore some advanced features for document analysis and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d1b385e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¬ Advanced Document Analysis\n",
      "============================================================\n",
      "ðŸ“Š Comparing documents on topic: the future impact of technology\n",
      "============================================================\n",
      "ðŸ¤– Analysis:\n",
      "Empty Response\n",
      "\n",
      "============================================================\n",
      "ðŸ“‹ Creating comprehensive document summary...\n",
      "============================================================\n",
      "ðŸ¤– Analysis:\n",
      "Empty Response\n",
      "\n",
      "============================================================\n",
      "ðŸ“‹ Creating comprehensive document summary...\n",
      "============================================================\n",
      "ðŸ“Š Document Collection Summary:\n",
      "Empty Response\n",
      "\n",
      "============================================================\n",
      "ðŸ”‘ Extracting key concepts and definitions...\n",
      "============================================================\n",
      "ðŸ“Š Document Collection Summary:\n",
      "Empty Response\n",
      "\n",
      "============================================================\n",
      "ðŸ”‘ Extracting key concepts and definitions...\n",
      "============================================================\n",
      "ðŸŽ“ Key Concepts:\n",
      "Empty Response\n",
      "ðŸŽ“ Key Concepts:\n",
      "Empty Response\n"
     ]
    }
   ],
   "source": [
    "# Advanced document analysis functions\n",
    "\n",
    "def compare_documents(topic, doc1_filter=None, doc2_filter=None):\n",
    "    \"\"\"Compare how different documents discuss a topic\"\"\"\n",
    "    \n",
    "    print(f\"ðŸ“Š Comparing documents on topic: {topic}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if doc1_filter and doc2_filter:\n",
    "        # Query each document separately\n",
    "        engine1 = create_document_specific_query_engine(doc1_filter)\n",
    "        engine2 = create_document_specific_query_engine(doc2_filter)\n",
    "        \n",
    "        if engine1 and engine2:\n",
    "            print(f\"ðŸ“„ Document 1: {doc1_filter}\")\n",
    "            response1 = engine1.query(f\"Explain {topic}\")\n",
    "            print(\"ðŸ¤– Response:\")\n",
    "            print(response1.response)\n",
    "            \n",
    "            print(f\"\\nðŸ“„ Document 2: {doc2_filter}\")\n",
    "            response2 = engine2.query(f\"Explain {topic}\")\n",
    "            print(\"ðŸ¤– Response:\")\n",
    "            print(response2.response)\n",
    "            \n",
    "            # Use the main engine to synthesize comparison\n",
    "            print(f\"\\nðŸ”„ Synthesizing comparison...\")\n",
    "            comparison_query = f\"\"\"\n",
    "            Based on the available documents, compare and contrast how {topic} is presented. \n",
    "            Highlight similarities and differences in the explanations, approaches, or perspectives.\n",
    "            \"\"\"\n",
    "            \n",
    "            comparison_response = advanced_query_engine.query(comparison_query)\n",
    "            print(\"\\nðŸŽ¯ Comparison Analysis:\")\n",
    "            print(comparison_response.response)\n",
    "    else:\n",
    "        # General comparison query\n",
    "        comparison_query = f\"\"\"\n",
    "        Compare and contrast the different perspectives or approaches to {topic} \n",
    "        found in the available documents. Highlight key similarities and differences.\n",
    "        \"\"\"\n",
    "        response = advanced_query_engine.query(comparison_query)\n",
    "        print(\"ðŸ¤– Analysis:\")\n",
    "        print(response.response)\n",
    "\n",
    "def summarize_document_collection():\n",
    "    \"\"\"Create a comprehensive summary of all documents\"\"\"\n",
    "    \n",
    "    print(\"ðŸ“‹ Creating comprehensive document summary...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    summary_query = \"\"\"\n",
    "    Provide a comprehensive summary of all the documents in the collection. \n",
    "    Include:\n",
    "    1. Main topics covered\n",
    "    2. Key concepts and definitions\n",
    "    3. Important relationships between topics\n",
    "    4. Overall themes and insights\n",
    "    \n",
    "    Structure your response clearly with headers and bullet points.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = advanced_query_engine.query(summary_query)\n",
    "    print(\"ðŸ“Š Document Collection Summary:\")\n",
    "    print(response.response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "def extract_key_concepts():\n",
    "    \"\"\"Extract key concepts and definitions from all documents\"\"\"\n",
    "    \n",
    "    print(\"ðŸ”‘ Extracting key concepts and definitions...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    concepts_query = \"\"\"\n",
    "    Extract and list the key concepts, terms, and definitions from all documents.\n",
    "    For each concept, provide:\n",
    "    1. The term/concept name\n",
    "    2. Its definition or explanation\n",
    "    3. Which document(s) it appears in\n",
    "    \n",
    "    Focus on important technical terms, main ideas, and fundamental concepts.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = advanced_query_engine.query(concepts_query)\n",
    "    print(\"ðŸŽ“ Key Concepts:\")\n",
    "    print(response.response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test advanced analysis features\n",
    "print(\"ðŸ”¬ Advanced Document Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compare how both documents discuss technology concepts\n",
    "compare_documents(\"the future impact of technology\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Get comprehensive summary\n",
    "summary_response = summarize_document_collection()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Extract key concepts\n",
    "concepts_response = extract_key_concepts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai-workflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
